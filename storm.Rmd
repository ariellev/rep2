---
title: "Severe Weather Events in the US between 1950 and 2011: Costs in Property and Public Health"
output: 
  html_document:
    keep_md: true
---

### Synopsis

This report is based on a NOAA Storm Dataset containing over 900K meteorological events gathered across the U.S. between 1950 and 2011. The meteorolgical events were categorized into 48 different types as specified in **Table 1: Storm Data** in [National Weather Service Instruction 10-1605.pdf](https://d396qusza40orc.cloudfront.net/repdata%2Fpeer2_doc%2Fpd01016005curr.pdf) . The focus of my study was to assess the damage caused by each event type to both property and public health. The ones with the highest average mortality rates are: tsunami (1.65) , heat (1.27), excessive heat (1.10) and rip current (0.73). There question of the correlation between injury and fatality rate is an interesting topic, but unfortunately will not be covered by the scope of this report. Flood, hurricane/typhoon and tornado are considered the most destructive events in terms of loss of property - with averagely more than 150, 85 and 57 Billions USD correspondly. As for the crops category, drought, flood and hurricane/typhoon are the most destructive with an average damage of 13.9, 10.8, 5.5 Billions USD each correspondly.

```{r,echo=F, message=F}
library(knitr)
opts_knit$set(cache=T)
```

### Data Processing
```{r,echo=T}
sessionInfo()
```

Loading required packages.
```{r,echo=T, message = F, cache=F}
detach(package:plyr)
require(dplyr)
require(ggplot2)
require(stringr)
```

Loading the dataset into R
```{r,echo=T}
# loading the dataset into R
d <- read.csv(bzfile("storm.bz2"), stringsAsFactors=F)

# dataset was downloaded from: "https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2"
# dataset was downloaded on:   "2015-04-18 07:37:06 CEST"

# exploring dimensions and variables
str(d)
```


The to the loss assement essential variables are listed in the table below. The rest of the variables can be ignored for the scope of our study - making our dataset more lightweight to work with. 

| variable        | description                 |
|:----------------|:----------------------------|
| EVTYPE          | event type                  |
| FATALITIES      | total fatalities            |
| INJURIES        | total injuries              |
| PROPDMG         | property damage - mantissa  |
| PROPDMGEXP      | property damage - exponent  |
| CROPDMG         | crop damage - mantissa      |
| CROPDMGEXP      | crop damage - exponent      |
| REMARKS         | additional information*     | 

* REMARKS is necessary in cases where EVTYPE is of a form of "Summary of.." 
```{r,echo=T}
# projecting dataset
cols <- c(8,23:28,36)
d <- d[,cols]
names(d)
```

The examination of the size of the unique values of EVTYPE yields a fairly bigger figure than the 48 permitted events by NOAA. We will therefore have to tidy up ETYPES and bring it to a more consistent state.
```{r,echo=T}
e_types <- d$EVTYPE
length(unique(e_types))
```

### Cleaning EVTYPE

In this section I would like to demonstrate a method to clean EVTYPE. The strategy would be in general to **automatically** find a best match between a given EVTYPE to a probable candidate in **Table 1**. To find such a match I will introduce a simple utility function written specficily for that purpose. Prior to finding a best match, we will have to reduce the noise, i.e the modficiations of simliar words to the ones in **Table 1**, and the complete removal of foreign. For that I will apply some simple techniches of string manipulations, such as replacement of non alphabetical character, and introduce a second utilty function that utilizes the filtering. My objective was to fully automate this process. However I could not avoid using one single manual step: copying the table from the pdf into a text file format. 

#### Basic string manipulations

```{r,echo=T}
# applying string manipulation to clean the EVTYPE variable
# upper Case
e_types <- toupper(e_types)
# removing non alphabetical chars
e_types <- gsub("[^A-Z ]", " ",  e_types)
# removing spaces
e_types <- gsub("[ ]+", " ",  e_types)
# trimming
e_types <- str_trim(e_types)

length(unique(e_types))
```

#### Copy Table 1
open [National Weather Service Instruction 10-1605.pdf](https://d396qusza40orc.cloudfront.net/repdata%2Fpeer2_doc%2Fpd01016005curr.pdf) and scroll down to page 6 to **Table 1 *Storm Data***, mark the table with the mouse, copy the content to a clipboard, create a text file called *"noaa_e_types.txt"*, and paste the clipboard into it.
Afterwards, based on the file's data, we will create two R variables *noaa_glossary* and *noaa_e_types*
```{r noaa_e_types.txt,echo=T}
system("head noaa_e_types.txt")
# Astronomical Low Tide Z
# Avalanche Z
# Blizzard Z
# Coastal Flood Z
# Cold/Wind Chill Z
# Debris Flow C
# Dense Fog Z
# Dense Smoke Z
# Drought Z
# Dust Devil C

# noaa_glossary is the word set of Table 1 
noaa_glossary <- scan("noaa_e_types.txt", what = "characters")
noaa_glossary <- unique(noaa_glossary)
noaa_glossary <- unlist(strsplit(noaa_glossary,"[^a-zA-Z]", fixed=F))
noaa_glossary <- noaa_glossary[nchar(noaa_glossary) > 1]
noaa_glossary <- toupper(noaa_glossary)
noaa_glossary <- noaa_glossary[order(noaa_glossary)]
noaa_glossary

# noaa_e_types is a set of permitted event types as listed in Table 1. 
noaa_e_types <- scan("noaa_e_types.txt", what = "characters", sep="\n")
noaa_e_types <- substr(noaa_e_types, 0, nchar(noaa_e_types) - 1)
noaa_e_types <- toupper(noaa_e_types)
noaa_e_types <- gsub("[^A-Z ]", " ",  noaa_e_types)
noaa_e_types <- gsub("[ ]+", " ",  noaa_e_types)
noaa_e_types <- str_trim(noaa_e_types)
noaa_e_types
```

#### Utility function: noaa_filter

```{r glossary,echo=T}
# declaring a filter utility function 
# input: string vector, dictionary, replacement string
noaa_filter <- function(s_vec, dictionary, replacement = "*") {
  # initializing result vector
  r_vec <- c()
  for (s in s_vec) {
    token <- ""
  	split <- unlist(strsplit(s, " "))
		for (w in split) {
      # lookup
			if (w %in% dictionary) {
			  token <- paste(token, w)
			} else {
 			  token <- paste(token, replacement)
			}
		}
    # tidying and appending to result vector
		token <- gsub("[ ]+", " ",  token)
		token <- str_trim(token)
		r_vec <- append(r_vec, token)
	}
	r_vec
}

# usage example
eu <- unique(e_types)
data.frame(before = eu[658:660], after = noaa_filter(eu[658:660], noaa_glossary, "(*)"))
```

#### Utility function: noaa_match

```{r,echo=T}
# declaring a utility function 
# input: string vector to be matched with candidates
noaa_match <- function(s_vec, candidates) {
  # initializing result vector  
  r_vec <- c()
  for (s in s_vec) {
  	split_s <- unlist(strsplit(s, " "))
		max_matchability <- 0
		match <- ""
		for ( c in candidates) {
		  split_c <- unlist(strsplit(c, " "))
		  matchability <- length(intersect(split_s, split_c)) / length(union(split_s, split_c)) 
		  if (matchability > max_matchability) {
			  max_matchability <- matchability
			  match <- c
		  }
		}
    # tidying and appending to result vector    
		r_vec <- append(r_vec, match)
	}
	r_vec
}

# usage example
data.frame(event = eu[6:9], match = noaa_match(eu[6:9], noaa_e_types))
```

#### Handling EVTYPE of the form of "Summary of .."

The information describing these type of events is given as a free text under the REMARKS variable. In this situtations we will match REMARKS with the events of **Table 1**.
```{r,echo=T}
# example
head(d[grepl(".*summary.*", e_types, ignore.case = T), 8],1)

# ratio 
e_summary <- grepl(".*summary.*", e_types, ignore.case = T)
data.frame( mean = mean(e_summary), total = sum(e_summary))


remarks <- d[e_summary, 8]
remarks <- toupper(remarks)
remarks <- noaa_filter(remarks, noaa_glossary, "")
remarks <- noaa_match(remarks, noaa_e_types)
remarks

e_types[e_summary] <- remarks
```

#### Modifying similar words
```{r example,echo=T}
u <- unique(e_types)
u[grepl("SNOW[A-Z]+", u)]

similarities <- c("FLOOD", "SNOW", "WIND", "WILDFIRES")
for (s in similarities) {
  regex <- paste0("[A-Z]*",s,"[A-Z]*")
  exp <- paste0(" ",s," ")
  e_types <- gsub( regex, exp, e_types)  
}

# abbreviations
e_types <- gsub("[A-Z]*TSTM[A-Z]*", " THUNDERSTORM ", e_types)

# removing spaces
e_types <- gsub("[ ]+", " ",  e_types)
# trimming
e_types <- str_trim(e_types)

eu <- unique(e_types)
length(eu)
```

#### Filtering EVTYPE

```{r,echo=T}
df0 <- data.frame(e_type=eu, e_filtered = noaa_filter(eu, noaa_glossary, ""), stringsAsFactors = F)
eu <- unique(df0$e_filtered)
length(eu)
```

#### Matching EVTYPE

```{r,echo=T}
df1 <- data.frame(e_filtered=eu, bool=eu %in% noaa_e_types, stringsAsFactors = F)
df1$e_match <- noaa_match(eu, noaa_e_types)
df1[!df1$bool,c(1,3)][148:155,]
```

#### Merging and integrating matches to the primary dataset *e_types*

```{r,echo=T, message = F}
# joining df0 and df1
df_0_1 <- left_join(df0,df1)
head(df_0_1)
df_0_1 <- df_0_1[,c(1,4)]
head(df_0_1)

# joining e_types and df_0_1
e_joined <- left_join(data.frame(e_type=e_types, stringsAsFactors = F),df_0_1)
sample_n(e_joined, 10)
e_types <- e_joined$e_match
d[,1] <- e_types

# excluding empty observations 
d <- d[nchar(d$EVTYPE) > 0,]
```

### Cleaning Property and Crop Variables

```{r,echo=T, message = F}
# property
prop_dmg_exp <- data.frame(PROPDMGEXP = d$PROPDMGEXP, stringsAsFactors = F)
unique(prop_dmg_exp$PROPDMGEXP)

# quite a lot of data is incomplete
mean(grepl("[- ?+]|(^$)", prop_dmg_exp$PROPDMGEXP))

magnitudes_chr = c("B", "b", "M", "m", "K", "k" , "H", "h", 9:0, "+", "-", "", "?")
magnitudes_num = c(9, 9, 6, 6, 3, 3, 2, 2, 9:0, 0, 0, 0, 0)
magnitudes <- data.frame(PROPDMGEXP = magnitudes_chr, value = magnitudes_num , stringsAsFactors=F)
head(magnitudes)

prop_dmg_exp_num <- left_join(prop_dmg_exp, magnitudes)
d$PROPDMGEXP <- prop_dmg_exp_num$value

# crop
crop_dmg_exp <- data.frame(CROPDMGEXP = d$CROPDMGEXP, stringsAsFactors = F)
unique(crop_dmg_exp$CROPDMGEXP)

# quite a lot of data is incomplete
mean(grepl("[- ?+]|(^$)", crop_dmg_exp$CROPDMGEXP))
magnitudes <- data.frame(CROPDMGEXP = magnitudes_chr, value = magnitudes_num , stringsAsFactors=F)

crop_dmg_exp_num <- left_join(crop_dmg_exp, magnitudes)
d$CROPDMGEXP <- crop_dmg_exp_num$value
```

### Results

#### Public Health

```{r,echo=T, message = F}
grp <- group_by(d, EVTYPE)
summarized <- summarize(grp, count = n(), fatalities = sum(FATALITIES), fatalities_mean = round(mean(FATALITIES),3), injuries = sum(INJURIES), injuries_mean = round(mean(INJURIES),3) )
summarized <- summarized %>% arrange(desc(fatalities_mean, injuries_mean)) 
summarized

melted <- melt(summarized[,c(1,4,6)], c("EVTYPE"))
melted$EVTYPE <- factor(summarized$EVTYPE,levels=summarized$EVTYPE)
qplot(EVTYPE, value, data = melted, fill = variable, geom = "bar") + geom_bar(stat="identity", size=.3) + theme(axis.text.x = element_text(angle = 90, hjust = 1)) +  ylab("Persons") + xlab("Event") + ggtitle(expression(atop("Average Fatality and Injury Rate in Number of Persons", atop("USA 1950 - 2011")))) + scale_fill_discrete(name="Type", labels=c("Fatality", "Injury"))
```

#### Property and Crops

```{r,echo=T, message = F}
grp_dmg <- filter(d, PROPDMG > 0 | CROPDMG > 0) %>% group_by(EVTYPE)
summarized_dmg <- mutate(grp_dmg, prop_dmg = PROPDMG*10^PROPDMGEXP, crop_dmg = CROPDMG*10^CROPDMGEXP) %>% summarize(count = n(), total_prop_dmg = sum(prop_dmg) / 10^9, total_crop_dmg = sum(crop_dmg) / 10^9) %>% mutate(sub_total_dmg = total_prop_dmg + total_crop_dmg) %>% arrange(desc(sub_total_dmg)) 
summarized_dmg

e_factor <- factor(summarized_dmg$EVTYPE,levels=summarized_dmg$EVTYPE)
melted <- melt(summarized_dmg[,c(1,3,4)], c("EVTYPE"))
melted$EVTYPE <- e_factor
qplot(EVTYPE, value, data = melted, fill = variable, geom = "bar") + geom_bar(stat="identity", size=.3) + theme(axis.text.x = element_text(angle = 90, hjust = 1)) +  ylab("Billions USD") + xlab("Event") + ggtitle(expression(atop("Total Damage to Properties and Crops in Billions of USD", atop("USA 1950 - 2011")))) + scale_fill_discrete(name="Type", labels=c("Properties", "Crops"))
```

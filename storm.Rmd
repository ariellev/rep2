---
title: "Reproducible Research: Peer Assessment 1"
output: 
  html_document:
    keep_md: true
---

##Synopsis
Bla Bla Bla

##Data Processing

```{r,echo=T, cache=T}
sessionInfo()
```

```{r,echo=T, cache=T, message = F}
require(dplyr)
require(plyr)
require(ggplo2)
require(stringr)
```

Loading the dataset into R
```{r,echo=T, cache=T}
# dataset was downloaded from: "https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2"
# dataset was downloaded on:   "2015-04-18 07:37:06 CEST"

# loading the dataset into R
d <- read.csv(bzfile("storm.bz2"), stringsAsFactors=F)
str(d)
```

Projecting dataset to contain only those relevant variables, which reflect damage to either health or property
```{r,echo=T, cache=T}
names(d)

# subsetting
cols <- c(8,23:28,36)
names(d)[cols]
d <- d[,cols]
```

Tiding up the event variable will be the focus of the follwing phase.
```{r,echo=T, cache=T}
e_types <- d$EVTYPE
length(unique(e_types))

# applying string manipulation to clean the EVTYPE variable
# Upper Case
e_types <- toupper(e_types)
# removing non alphabetical chars
e_types <- gsub("[^A-Z ]", " ",  e_types)
# removing spaces
e_types <- gsub("[ ]+", " ",  e_types)
# trimming
e_types <- str_trim(e_types)

length(unique(e_types))
```

There's still away to go. The pdf blabla tells us in section blabla that there are 48 approved event types.example:
```{r,echo=T, cache=T}
u <- unique(e_types)
u[grepl("SNOW[A-Z]+", u)]
```

```{r,echo=T, cache=T}
e_types <- gsub("[A-Z]*FLOOD[A-Z]*", " FLOOD ", e_types)
e_types <- gsub("[A-Z]*SNOW[A-Z]*", " SNOW ", e_types)
e_types <- gsub("[A-Z]*WILDFIRES[A-Z]*", " WILDFIRES ", e_types)
e_types <- gsub("[A-Z]*TSTM[A-Z]*", " THUNDERSTORM ", e_types)
length(unique(e_types))
```
Replacement of summary
```{r,echo=T, cache=T}
# TODO
```

NOAA noaa_glossary.
Example on non existing term
```{r,echo=T, cache=T}
# TODO
```

manual step : goto pdf copy paste into bla
```{r,echo=T, cache=T}
noaa_glossary <- scan("noaa_e_types.txt", what = "characters")
noaa_glossary <- unique(noaa_glossary)
noaa_glossary <- unlist(strsplit(noaa_glossary,"[^a-zA-Z]", fixed=F))
noaa_glossary <- noaa_glossary[nchar(noaa_glossary) > 1]
noaa_glossary <- toupper(noaa_glossary)
noaa_glossary <- noaa_glossary[order(noaa_glossary)]
noaa_glossary

# declaring a utility function 
noaa_filter <- function(s_vec, dictionary, replacement = "*") {
  r_vec <- c()
	for (s in s_vec) {
		token <- ""
		split <- unlist(strsplit(s, " "))
		for (w in split) {
			if (w %in% dictionary) {
			  token <- paste(token, w)
			} else {
 			  token <- paste(token, replacement)
			}
		}
		token <- gsub("[ ]+", " ",  token)
		token <- str_trim(token)
		r_vec <- append(r_vec, token)
	}
	r_vec
}

# usage example
eu <- unique(e_types)
data.frame(before = eu[658:660], after = noaa_filter(eu[658:660], noaa_glossary, "(*)"))

df0 <- data.frame(e_type=eu, e_filtered = noaa_filter(eu, noaa_glossary, ""))
eu <- unique(df0$e_filtered)
length(eu)
```

finding a match
example
```{r,echo=T, cache=T}
# TODO
```

```{r,echo=T, cache=T}
noaa_e_types <- scan("noaa_e_types.txt", what = "characters", sep="\n")
noaa_e_types <- substr(noaa_e_types, 0, nchar(noaa_e_types) - 1)
noaa_e_types <- toupper(noaa_e_types)
noaa_e_types <- gsub("[^A-Z ]", " ",  noaa_e_types)
noaa_e_types <- gsub("[ ]+", " ",  noaa_e_types)
noaa_e_types <- str_trim(noaa_e_types)
noaa_e_types

# declaring a utility function 
noaa_match <- function(s_vec, with_vec) {
  r_vec <- c()
	for (s in s_vec) {
		split_s <- unlist(strsplit(s, " "))
		found_total <- 0
		found_word <- ""
		for ( w in with_vec) {
		  split_w <- unlist(strsplit(w, " "))
		  inter <- length(intersect(split_s, split_w)) / length(union(split_s, split_w)) 
		  if (inter > found_total) {
			found_total <- inter
			found_word <- w
		  }
		}
		r_vec <- append(r_vec, found_word)
	}
	r_vec
}

# usage example
data.frame(event = eu[1:3], match = noaa_match(eu[1:3], noaa_e_types))

df1 <- data.frame(e_filtered=eu, bool=eu %in% noaa_e_types)
df1$e_match <- noaa_match(eu, noaa_e_types)
df1[!df1$bool,c(1,3)][148:155,]
```

To complete the phase, lets merge df0, df1 and e_types
```{r,echo=T, cache=T}
# joining df0 and df1
df_0_1 <- join(df0,df1)
head(df_0_1)
df_0_1 <- df_0_1[,c(1,4)]
head(df_0_1)

# joining e_types and df_0_1
e_joined <- join(data.frame(e_type=e_types),df_0_1)
sample(e_joined)
e_types <- e_joined$e_match
d[,1] <- e_types

# excluding empty observations 
d <- d[nchar(d$EVTYPE) > 0,]
```

Group and summarize
```{r,echo=T, cache=F, message = F}
#library(dplyr)
#grp <- group_by(d, EVTYPE)
#summarized <- summarize(grp, count = n(), fatalities = sum(FATALITIES), fatalities_mean = round(mean(FATALITIES),3), #injuries = sum(INJURIES), injuries_mean = round(mean(INJURIES),3) )
#summarized <- summarized %>% arrange(desc(fatalities_mean, injuries_mean)) 
#summarized
```
##Results